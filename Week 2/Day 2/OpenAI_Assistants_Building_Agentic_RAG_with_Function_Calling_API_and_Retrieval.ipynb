{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgDepNVhvzIr"
      },
      "source": [
        "# OpenAI Assistants - Building Agentic RAG with the Function Calling, Retrieval, and Code Interpreter Tools\n",
        "\n",
        "Today we'll explore using OpenAI's Python SDK to create, manage, and use the OpenAI Assistant API!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNU6b3ymwOWq"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "We'll start, as we usually do, with some dependiencies and our API key!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ePayyL6at6LS"
      },
      "outputs": [],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unKr3HZdu-1V",
        "outputId": "610aeddb-5e56-4d75-e399-59054435c2ef"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwNE7N4HwhXH"
      },
      "source": [
        "## Simple Assistant\n",
        "\n",
        "Let's create a simple Assistant to understand more about how the API works to start!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKEwbLMFxNKs"
      },
      "source": [
        "### OpenAI Client\n",
        "\n",
        "At the core of the OpenAI Python SDK is the Client!\n",
        "\n",
        "> NOTE: For ease of use, we'll start with the synchronous `OpenAI()`. OpenAI does provide an `AsyncOpenAI()` that you could leverage as well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wF-mBZwtuavl"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aIx4GZ2w_1c"
      },
      "source": [
        "### Creating An Assistant\n",
        "\n",
        "Leveraging what we know about the OpenAI API from previous sessions - we're going to start by simply initializing an Assistant.\n",
        "\n",
        "Before we begin, we need to think about a few customization options we have:\n",
        "\n",
        "- `name` - Straight forward enough, this is what our Assistant's name will be\n",
        "- `instructions` - similar to a system message, but applied at an Assistant level, this is how we can guide the Assistant's tone, behaviour, functionality, and more!\n",
        "- `model` - this will allow us to choose which model we would prefer to use for our Assistant\n",
        "\n",
        "Let's start by setting some instructions for our Assistant.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "Paqd6zWMyMAJ"
      },
      "outputs": [],
      "source": [
        "# @markdown #### 🏗️ Build Activity 🏗️\n",
        "# @markdown Fill out the fields below to add your Assistant's name, instructions, and desired model!\n",
        "\n",
        "name = \"Pebble\" # @param {type: \"string\"}\n",
        "instructions = \"You are great in coming up with ideas for garden landscaping.\" # @param {type: \"string\"}\n",
        "model = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4-turbo-preview\", \"gpt-4\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUeaDsLMzcv-"
      },
      "source": [
        "### Initialize Assistant\n",
        "\n",
        "Now that we have our desired name, instruction, and model - we can initialize our Assistant!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6-4MgVLbu8rO"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name,\n",
        "    instructions=instructions,\n",
        "    model=model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QskO5n5W2X6t"
      },
      "source": [
        "Let's examine our `assistant` object and see what we find!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkkIC_JP2bG0",
        "outputId": "a1646ea4-dc68-4a3d-f997-c3e7f0fd7abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Assistant(id='asst_jPr7PjPHDDak55gdmkOUalFz', created_at=1713244157, description=None, file_ids=[], instructions='You are great in coming up with ideas for garden landscaping.', metadata={}, model='gpt-3.5-turbo', name='Pebble', object='assistant', tools=[], top_p=1.0, temperature=1.0, response_format='auto')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "615NK1Qj2e_Z"
      },
      "source": [
        "There are a number of useful parameters here, but we'll call out a few:\n",
        "\n",
        "- `id` - since we may have multiple Assistant's, knowing which Assistant we're interacting with will help us ensure the desired user experience!\n",
        "- `description` - A natrual language description of our Assistant could help others understand what it's supposed to do!\n",
        "- `file_ids` - if we wanted to use the Retrieval tool, this would let us know what files we had given our Assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3HhlqtM0AhW"
      },
      "source": [
        "### Creating a Thread\n",
        "\n",
        "Behind the scenes our Assistant is powered by the idea of \"threads\".\n",
        "\n",
        "You can think of threads as individual conversations that interact with the Assistant.\n",
        "\n",
        "Let's create a thread now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iFVM39vevT5f"
      },
      "outputs": [],
      "source": [
        "thread = client.beta.threads.create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y7jelq01PoG"
      },
      "source": [
        "Let's look at our `thread` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8WAKDZ1Uf2",
        "outputId": "4678aaef-3c01-4876-8136-334897074ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Thread(id='thread_JRRyAFaPcJUFBUqLpmupzvsi', created_at=1713244210, metadata={}, object='thread')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k6S_e501V4z"
      },
      "source": [
        "Notice some key attributes:\n",
        "\n",
        "- `id` - since each Thread is like a conversation, we need some way to specify which thread we're dealing with when interacting with them\n",
        "- `tool_resources` - this will become more relevant as we add tools since we'll need a way to verify which tools we have access to when interacting with our Assistant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5BvGv1N0c2h"
      },
      "source": [
        "### Adding Messages to Our Thread\n",
        "\n",
        "Now that we have our Thread (or conversation) we can start adding messages to it!\n",
        "\n",
        "Let's add a simple message that asks about how our Assistant is feeling.\n",
        "\n",
        "Notice the parameters we're leveraging:\n",
        "\n",
        "- `thread_id` - since each Thread is like a conversation, we need some way to address a specific conversation. We can use `thread.id` to do this.\n",
        "- `role` - similar to when we used our chat completions endpoint, this parameter specifies who the message is coming from. You can leverage this in the same ways you would through the chat completions endpoint.\n",
        "- `content` - this is where we can place the actual text our Assistant will interact with\n",
        "\n",
        "> NOTE: Feel free to substitute a relevant message based on the Assistant you created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "R7ZNCfGivagg"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=f\"Pebble, help me layout a vegetable garden plan that maximizes space.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc7R3Sr32P0b"
      },
      "source": [
        "Again, let's examine our `message` object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMLvyZDA2S_D",
        "outputId": "5076c8e4-0970-44ff-c609-1501a53cfe1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_l4dc8MDQPFPj64wczOOVizmm', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Pebble, help me layout a vegetable garden plan that maximizes space.'), type='text')], created_at=1713244432, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_JRRyAFaPcJUFBUqLpmupzvsi')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI3Pctpk29og"
      },
      "source": [
        "### Running Our Thread\n",
        "\n",
        "Now that we have an Assistant, and we've given that Assistant a Thread, and we've added a Message to that Thread - we're ready to run our Assistant!\n",
        "\n",
        "Notice that this process lets us add (potentially) multiple messages to our Assistant. We can leverage that behaviour for few/many-shot examples, and more!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "VkvsXv5_3cyQ"
      },
      "outputs": [],
      "source": [
        "# @markdown #### 🏗️ Build Activity 🏗️\n",
        "# @markdown We can also override the Assistant's instructions when we run a thread.\n",
        "\n",
        "# @markdown Use one of the [Prompt Principles for Instruction](https://arxiv.org/pdf/2312.16171v1.pdf) to improve the likeliehood of a correct or valuable response from your Assistant.\n",
        "\n",
        "additional_instructions = \"think step by step\" # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CuGbTrL5QEc"
      },
      "source": [
        "Let's run our Thread!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fpWNl3UVvdW4"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        "  instructions=instructions + \" \" + additional_instructions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erMGdU7y6la2"
      },
      "source": [
        "Now that we've run our thread, let's look at the object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz_rfwi869YI",
        "outputId": "9b0df335-c3a9-43a5-f7c0-020e37679c8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Run(id='run_Kx2LdMzAp4Jqeoq7l0KP2a1y', assistant_id='asst_jPr7PjPHDDak55gdmkOUalFz', cancelled_at=None, completed_at=None, created_at=1713244549, expires_at=1713245149, failed_at=None, file_ids=[], incomplete_details=None, instructions='You are great in coming up with ideas for garden landscaping. think step by step', last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo', object='thread.run', required_action=None, response_format='auto', started_at=None, status='queued', thread_id='thread_JRRyAFaPcJUFBUqLpmupzvsi', tool_choice='auto', tools=[], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h2SH_347JJb"
      },
      "source": [
        "Notice we have access to a few very powerful parameters in this `run` object.\n",
        "\n",
        "- `completed_at` - this will help us determine when we can expect to retrieve a response\n",
        "- `failed_at` - this can highlight any issues our run ran into\n",
        "- `status` - is another way we can understand how the flow is going"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVBNagBU7kpx"
      },
      "source": [
        "### Retrieving Our Run\n",
        "\n",
        "Now that we've created our run, let's retrieve it.\n",
        "\n",
        "We're going to wrap this in a simple loop to make sure we're not retrieving it too early."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "itz5_otPvfkV"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgGE1uUJ7z3h",
        "outputId": "174572f2-fcb6-4b5e-9ad0-6a6b9c413f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "completed\n"
          ]
        }
      ],
      "source": [
        "print(run.status)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHVTS4hD7-fv"
      },
      "source": [
        "Now that our run is completed - we can retieve the messages from our thread!\n",
        "\n",
        "Notice that our run helps us understand how things are going - but it isn't where we're going to find our responses or messages. Those are added on the backend into our thread.\n",
        "\n",
        "This leads to a simple, but important, flow:\n",
        "\n",
        "1. We add messages to a thread.\n",
        "2. We create a run on that thread.\n",
        "3. We wait until the run is finished.\n",
        "4. We check our thread for the new messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGBNpGmh-ZpW"
      },
      "source": [
        "### Checking Our Thread\n",
        "\n",
        "Now we can get a list of messages from our thread!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Av-OQDUPvhAd"
      },
      "outputs": [],
      "source": [
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM6cZk-GviqX",
        "outputId": "03f1a135-ce62-42e4-9e5e-203c91ffaf83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Message(id='msg_Hayhtc4gxTzI7Fcui3CszDJz', assistant_id='asst_jPr7PjPHDDak55gdmkOUalFz', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Sure! Here is a step-by-step guide to help you create a vegetable garden plan that maximizes space using pebbles as a decorative element:\\n\\n1. Measure the available space: Start by measuring the area where you want to create your vegetable garden. Note any obstacles such as trees, fences, or other structures that may impact the layout.\\n\\n2. Design your garden layout: Sketch out a rough design of your vegetable garden layout. Consider using raised beds or containers to maximize space and make it easier to maintain. Divide the space into sections for different types of vegetables, herbs, and flowers.\\n\\n3. Create pathways: Use pebbles to create defined pathways between the different sections of your vegetable garden. This will not only help with navigation but also add a decorative element to your garden.\\n\\n4. Use pebbles for edging: Use pebbles to create borders or edging around your raised beds or containers. This will help define the boundaries of each section and prevent grass and weeds from encroaching on your vegetable garden.\\n\\n5. Mulch with pebbles: Consider using pebbles as mulch around your vegetable plants. This will help conserve moisture in the soil, suppress weeds, and add a decorative touch to your garden.\\n\\n6. Install irrigation system: To maximize space in your vegetable garden, consider installing a drip irrigation system. This will ensure that your plants receive the right amount of water without wasting any valuable space.\\n\\n7. Plant strategically: When planting your vegetables, consider using companion planting techniques to maximize space and improve the overall health and productivity of your garden. For example, planting tall plants like tomatoes next to shorter plants like lettuce can help maximize sunlight and space.\\n\\n8. Maintain and enjoy: Once your vegetable garden is planted, be sure to maintain it regularly by watering, weeding, and harvesting your crops. Take the time to enjoy the fruits of your labor and watch your garden thrive throughout the growing season.\\n\\nBy following these steps and incorporating pebbles into your vegetable garden design, you can create a beautiful and functional space that maximizes productivity and enhances the overall aesthetics of your outdoor space. Happy gardening!'), type='text')], created_at=1713244550, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_Kx2LdMzAp4Jqeoq7l0KP2a1y', status=None, thread_id='thread_JRRyAFaPcJUFBUqLpmupzvsi')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages.data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgnY16tjCmc6"
      },
      "source": [
        "## Adding Tools\n",
        "\n",
        "Now that we have an understanding of how Assistant works, we can start thinking about adding tools.\n",
        "\n",
        "We'll go through 3 separate tools and explore how we can leverage them!\n",
        "\n",
        "Let's start with the most familiar tool - the Retriever!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0NagnlZC8g9"
      },
      "source": [
        "### Creating an Assistant with the Retriever Tool\n",
        "\n",
        "The first thing we'll want to do is create an assistant with the Retriever tool.\n",
        "\n",
        "This is also going to require some data. We'll provided data - but you're very much encouraged to use your own files to explore how the Assistant works for your use case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HInYwNiQEjQH"
      },
      "source": [
        "#### Collect and Add Data\n",
        "\n",
        "First, we need some data. Second, we need to add the data to our Assistant!\n",
        "\n",
        "Let's start with grabbing some data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wvAHBszIEa1Y"
      },
      "outputs": [],
      "source": [
        "!wget https://www.gutenberg.org/files/84/84-h/84-h.htm -o frankenstein.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2EpY1w_FQ3m"
      },
      "source": [
        "Now we can upload our file!\n",
        "\n",
        "Pay attention to [this](https://platform.openai.com/docs/assistants/tools/supported-files) documentation to see what kinds of files can be uploaded.\n",
        "\n",
        "> NOTE: Per the OpenAI [docs](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) The maximum file size is 512 MB and no more than 2,000,000 tokens (computed automatically when you attach a file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dpVoe2SMFI6s"
      },
      "outputs": [],
      "source": [
        "file_reference = client.files.create(\n",
        "  file=open(\"frankenstein.html\", \"rb\"),\n",
        "  purpose='assistants'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBQOSGyyF2u5"
      },
      "source": [
        "Let's look at what our `file_reference` contains!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJrVLkMpFgwf",
        "outputId": "b8e8d01a-faf8-4308-cc49-54c11415e245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-UOUQLfLNOKThQNRYGKEvsIvx', bytes=1200, created_at=1713246476, filename='frankenstein.html', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_reference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd4O4dpZF-eH"
      },
      "source": [
        "#### Create and Use Assistant\n",
        "\n",
        "Now that we have our file - we can attach it to an Assistant, and we can give that Assistant the ability to use it for retrieval through the Retrieval tool!\n",
        "\n",
        "> NOTE: Please pay attention to [pricing](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval) and don't forget to delete your files when you're done!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jfn_MlJqFiEe"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=name + \"+ Retrieval\",\n",
        "  instructions=instructions,\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"retrieval\"}],\n",
        "  file_ids=[file_reference.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0-mmRjQGeUR"
      },
      "source": [
        "Let's try submitting a message to our Assistant and seeing what kind of answer we get!\n",
        "\n",
        "We'll outline the steps needed to do this in full:\n",
        "\n",
        "1. Create an Assistant\n",
        "2. Create a Thread\n",
        "3. Add Messages to that Thread\n",
        "4. Create a Run on that Thread\n",
        "5. Wait for Run to Complete\n",
        "6. Collect Messages from the Thread\n",
        "\n",
        "Let's do that below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOKtb9PsGiB1",
        "outputId": "043ecfc0-2277-4b39-ba6b-fdf8a741e70f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queued\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n"
          ]
        }
      ],
      "source": [
        "# Create a Thread\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Add Messages to that Thread\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=f\"What is the first words Victor Frankenstein speaks?\"\n",
        ")\n",
        "\n",
        "# Create a Run on that Thread\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for Run to Complete\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  print(run.status)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "# Collect Messages from the Thread\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxJfa-saHbNQ"
      },
      "source": [
        "Let's look at the final result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19nDqjRgHaNA",
        "outputId": "f4ad3574-2056-4253-d406-f7057ef73dae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[Message](data=[Message(id='msg_upsOc3lXz8Y2ea90wxclt3DR', assistant_id='asst_EOZtFQxWpWmPUY6CVrsiFZNe', completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=226, file_citation=FileCitation(file_id='file-UOUQLfLNOKThQNRYGKEvsIvx', quote=''), start_index=213, text='【19:0†source】', type='file_citation')], value='The first words spoken by Victor Frankenstein are: \"You seek for knowledge and wisdom, as I once did; and I ardently hope that the gratification of your wishes may not be a serpent to sting you, as mine has been.\"【19:0†source】.'), type='text')], created_at=1713279591, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_xHZuLN5mXzOpZhWGTc3hOCAC', status=None, thread_id='thread_w1TumrsrBjFPs4LAtPqd19bl'), Message(id='msg_GidFDXY1MK5kSfVr2Fq48lMO', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What is the first words Victor Frankenstein speaks?'), type='text')], created_at=1713279580, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_w1TumrsrBjFPs4LAtPqd19bl')], object='list', first_id='msg_upsOc3lXz8Y2ea90wxclt3DR', last_id='msg_GidFDXY1MK5kSfVr2Fq48lMO', has_more=False)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JdzJDvmHyNF"
      },
      "source": [
        "Let's do some clean up to make sure we're not being charged anything extra by deleting our resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "01EYWyWBHaoC"
      },
      "outputs": [],
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pln9uYoJICno"
      },
      "source": [
        "### Creating an Assistant with the Code Interpreter Tool\n",
        "\n",
        "Now that we've explored the Retrieval Tool - let's try the Code Interpreter tool!\n",
        "\n",
        "The process will be almost exactly the same - but we can explore a different query, and we'll add our file at the Message level!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "IC81y_VtH9lw"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=name + \"+ Code Interpreter\",\n",
        "  instructions=instructions,\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"code_interpreter\"}],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJPHAJCQJbgi"
      },
      "source": [
        "In the following example, we'll also see how we can package the Thread creation with the Message adding step!\n",
        "\n",
        "> NOTE: Files added at the message/thread level will not be available to the Assistant outside of that Thread."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5xVdjH6EJQrr"
      },
      "outputs": [],
      "source": [
        "thread = client.beta.threads.create(\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"What kind of file is this?\",\n",
        "      \"file_ids\": [file_reference.id]\n",
        "    }\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiIYut_dJ0Cv"
      },
      "source": [
        "> NOTE: Remember that we create runs at the *thread* level - and so don't need the message object to continue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ES8laUe_Jwp_",
        "outputId": "7a9b004f-d824-4cca-f21f-bbbd9a55c4c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "queued\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n",
            "in_progress\n"
          ]
        }
      ],
      "source": [
        "# Create a Run on that Thread\n",
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "# Wait for Run to Complete\n",
        "while run.status == \"in_progress\" or run.status == \"queued\":\n",
        "  time.sleep(1)\n",
        "  print(run.status)\n",
        "  run = client.beta.threads.runs.retrieve(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        "  )\n",
        "\n",
        "# Collect Messages from the Thread\n",
        "messages = client.beta.threads.messages.list(\n",
        "  thread_id=thread.id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYPpGJz5KoDf"
      },
      "source": [
        "We can check the specific steps that the Code Interpreter ran to figure out what steps the Assistant took!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "or7iJ492KI2P"
      },
      "outputs": [],
      "source": [
        "run_steps = client.beta.threads.runs.steps.list(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwbzExbmKJ4N",
        "outputId": "da00f537-adda-46ac-9a98-79478751e28f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_DYb4C4GwyujyrAObnCnj0etb'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeInterpreterToolCall(id='call_h869SMSIJaNVPpfRj5MaGsbU', code_interpreter=CodeInterpreter(input=\"# Function to read the first few bytes of the file\\r\\ndef read_file_header(file_path, num_bytes=16):\\r\\n    with open(file_path, 'rb') as file:\\r\\n        header = file.read(num_bytes)\\r\\n    return header\\r\\n\\r\\n# Read the first 16 bytes of the file\\r\\nfile_header = read_file_header(file_path, num_bytes=16)\\r\\nfile_header\", outputs=[CodeInterpreterOutputLogs(logs=\"b'--2024-04-16 01:'\", type='logs')]), type='code_interpreter')], type='tool_calls')\n",
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_xMMCLz9IkVsPfTzrVjhQ9405'), type='message_creation')\n",
            "ToolCallsStepDetails(tool_calls=[CodeInterpreterToolCall(id='call_EYACp1p04bAcBeGI2Z5rssIU', code_interpreter=CodeInterpreter(input=\"import os\\r\\n\\r\\n# Get the file name and extension\\r\\nfile_path = '/mnt/data/file-UOUQLfLNOKThQNRYGKEvsIvx'\\r\\nfile_name, file_extension = os.path.splitext(file_path)\\r\\n\\r\\nfile_extension\", outputs=[CodeInterpreterOutputLogs(logs=\"''\", type='logs')]), type='code_interpreter')], type='tool_calls')\n",
            "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_WpYkb5ssZqBXRSkdjT7GTwY7'), type='message_creation')\n"
          ]
        }
      ],
      "source": [
        "for step in run_steps.data:\n",
        "  print(step.step_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNJeFF6JJ62H",
        "outputId": "d7565eca-5f49-429d-9d4a-220e22d746c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[Message](data=[Message(id='msg_DYb4C4GwyujyrAObnCnj0etb', assistant_id='asst_VyYOGAAjBAbQM7h1u06vYmKk', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"The first few bytes of the file are `--2024-04-16 01:`, which doesn't give a clear indication of the file type. At this point, it's not immediately apparent what kind of file this is based on the header. \\n\\nIf you have any information about the file type or its expected contents, please let me know. Otherwise, we can try opening the file with different applications or examining its contents in different ways to determine its type. Let me know how you would like to proceed.\"), type='text')], created_at=1713279666, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_mwGyCSlofqWrmEurxiwK2qKz', status=None, thread_id='thread_6HhdcQxWPp56vO8x1xQ4GpqS'), Message(id='msg_xMMCLz9IkVsPfTzrVjhQ9405', assistant_id='asst_VyYOGAAjBAbQM7h1u06vYmKk', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"It seems that the file extension is not provided or it might not be a standard one. Let's try to determine the type of the file by reading its contents. I will go ahead and read the first few bytes of the file to see if we can identify the file type based on its header. Let's check that now.\"), type='text')], created_at=1713279661, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_mwGyCSlofqWrmEurxiwK2qKz', status=None, thread_id='thread_6HhdcQxWPp56vO8x1xQ4GpqS'), Message(id='msg_WpYkb5ssZqBXRSkdjT7GTwY7', assistant_id='asst_VyYOGAAjBAbQM7h1u06vYmKk', completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value=\"Let's start by identifying the type of file you uploaded. I'll check the file extension to determine its format. Let's do that now.\"), type='text')], created_at=1713279658, file_ids=[], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_mwGyCSlofqWrmEurxiwK2qKz', status=None, thread_id='thread_6HhdcQxWPp56vO8x1xQ4GpqS'), Message(id='msg_yDgzVRYPh2KF9RDha4ht4rXf', assistant_id=None, completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='What kind of file is this?'), type='text')], created_at=1713279634, file_ids=['file-UOUQLfLNOKThQNRYGKEvsIvx'], incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_6HhdcQxWPp56vO8x1xQ4GpqS')], object='list', first_id='msg_DYb4C4GwyujyrAObnCnj0etb', last_id='msg_yDgzVRYPh2KF9RDha4ht4rXf', has_more=False)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi10hON2LQmc"
      },
      "source": [
        "And there you go!\n",
        "\n",
        "We've fit our Assistant with an awesome Code Interpreter that lets our Assistant run code on our provided files!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdJxt77oLzu7"
      },
      "source": [
        "### Creating an Assistant with a Function Calling Tool\n",
        "\n",
        "Let's finally create an Assistant that utilizes the Function Calling API.\n",
        "\n",
        "We'll start by creating a function that we wish to be called.\n",
        "\n",
        "We'll utilize DuckDuckGo search to allow our Assistant to have the most up to date information!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5eKEC2wMMVI",
        "outputId": "8077815f-153d-4e9f-c315-74c12035bde7"
      },
      "outputs": [],
      "source": [
        "!pip install -qU duckduckgo_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "YPFZ_Uq_LawH"
      },
      "outputs": [],
      "source": [
        "from duckduckgo_search import DDGS\n",
        "\n",
        "def duckduckgo_search(query):\n",
        "  with DDGS() as ddgs:\n",
        "    results = [r for r in ddgs.text(query, max_results=5)]\n",
        "    return \"\\n\".join(result[\"body\"] for result in results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-o1TBFpMSvR"
      },
      "source": [
        "Let's test our function to make sure it behaves as we expect it to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "mCUr9jFCMWBw",
        "outputId": "368ab562-a1f1-4660-d07b-4e597cdc9fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Lowry has been a part of the Jets organization since June 25, 2011, when he was selected in the third round, 67 th overall, after putting up 37 points in 36 games with the Swift Current Broncos of ...\\nAdam Lowry, who has been a Jet since 2011 when he was drafted 67th overall, is the new captain of the NHL team — its third since relocating to Winnipeg from Atlanta in 2011. Andrew Ladd served ...\\nLowry will follow Andrew Ladd and Blake Wheeler to serve as the third captain of the new Winnipeg Jets franchise. - Sep 12, 2023. After a season without a captain, the Winnipeg Jets have named ...\\nWinnipeg played without a captain last season after stripping Blake Wheeler of the title in September. Lowry is entering his 10th season with the Jets, who drafted him in the third round in 2011.\\nThe Winnipeg Jets have officially made the decision on which player will wear the captain's 'C' for the 2023-24 season, and hopefully onward. That player is 30-year-old centre Adam Lowry.\""
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "duckduckgo_search(\"Who is the current captain of the Winnipeg Jets?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzE1nxt5Mi80"
      },
      "source": [
        "Now we need to express how our function works in a way that is compatible with the OpenAI Function Calling API.\n",
        "\n",
        "We'll want to provide a `JSON` object that includes what parameters we have, how to call them, and a short natural language description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8ElrWvBnMY_s"
      },
      "outputs": [],
      "source": [
        "ddg_function = {\n",
        "    \"name\" : \"duckduckgo_search\",\n",
        "    \"description\" : \"Answer non-technical questions. \",\n",
        "    \"parameters\" : {\n",
        "        \"type\" : \"object\",\n",
        "        \"properties\" : {\n",
        "            \"query\" : {\n",
        "                \"type:\" : \"string\",\n",
        "                \"description\" : \"The search query to use. For example: 'Who is the current Goalie of the Colorado Avalance?'\"\n",
        "            }\n",
        "        },\n",
        "        \"required\" : [\"query\"]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyRmJgEQVuGs"
      },
      "source": [
        "####❓ Question\n",
        "\n",
        "Why does the description key-value pair matter?\n",
        "\n",
        "Answer - It is used by the LLM to pick the appropriate tool based on the prompt it receives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tir4WySGM0x2"
      },
      "source": [
        "Now when we create our Assistant - we'll want to include the function description as a tool using the following format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "4eFpwi12Mzlg"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name + \" + Function Calling API\",\n",
        "    instructions=instructions,\n",
        "    tools=[\n",
        "        {\"type\": \"function\",\n",
        "         \"function\" : ddg_function\n",
        "        }\n",
        "    ],\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJCLvWZzNIXR"
      },
      "source": [
        "We need to make a few modifications to our Assistant to include the ability to make calls to our local function and pass the results back to our Assistant for further generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "XHRfvGJ_NQnF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def wait_for_run_completion(thread_id, run_id):\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
        "        print(f\"Current run status: {run.status}\")\n",
        "        if run.status in ['completed', 'failed', 'requires_action']:\n",
        "            return run\n",
        "\n",
        "def submit_tool_outputs(thread_id, run_id, tools_to_call):\n",
        "    tool_output_array = []\n",
        "    for tool in tools_to_call:\n",
        "        output = None\n",
        "        tool_call_id = tool.id\n",
        "        function_name = tool.function.name\n",
        "        function_args = tool.function.arguments\n",
        "\n",
        "        if function_name == \"duckduckgo_search\":\n",
        "            print(\"Consulting Duck Duck Go...\")\n",
        "            output = duckduckgo_search(query=json.loads(function_args)[\"query\"])\n",
        "\n",
        "        if output:\n",
        "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
        "\n",
        "    print(tool_output_array)\n",
        "\n",
        "    return client.beta.threads.runs.submit_tool_outputs(\n",
        "        thread_id=thread_id,\n",
        "        run_id=run_id,\n",
        "        tool_outputs=tool_output_array\n",
        "    )\n",
        "\n",
        "def print_messages_from_thread(thread_id):\n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
        "    for msg in messages:\n",
        "        print(f\"{msg.role}: {msg.content[0].text.value}\")\n",
        "\n",
        "def use_assistant(query, assistant_id, thread_id=None):\n",
        "  thread = client.beta.threads.create()\n",
        "\n",
        "  message = client.beta.threads.messages.create(\n",
        "      thread_id=thread.id,\n",
        "      role=\"user\",\n",
        "      content=query,\n",
        "  )\n",
        "\n",
        "  print(\"Creating Assistant \")\n",
        "\n",
        "  run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant_id,\n",
        "  )\n",
        "\n",
        "  print(\"Querying OpenAI Assistant Thread.\")\n",
        "\n",
        "  run = wait_for_run_completion(thread.id, run.id)\n",
        "\n",
        "  if run.status == 'requires_action':\n",
        "    run = submit_tool_outputs(thread.id, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
        "    run = wait_for_run_completion(thread.id, run.id)\n",
        "\n",
        "  print_messages_from_thread(thread.id)\n",
        "\n",
        "  return thread.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoChJ771Uo0B"
      },
      "source": [
        "####❓ Question\n",
        "\n",
        "Outline, in simple terms, what the `use_assistant` helper function is doing.\n",
        "\n",
        "Answer - The function initiates a conversation with the assistant by creating a thread and logging the user's input as a message in that thread. It then executes the thread and monitors it until completion. If the execution status indicates that a tool is required, the function triggers the corresponding tool, produces the necessary output, and links this output to a new run using the `submit_tools_output` method. The function then waits for this new run to finish and subsequently retrieves the messages from the completed run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5NR_HYINky8",
        "outputId": "60042cd6-117f-423e-9f75-5ea1d663c602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: requires_action\n",
            "Consulting Duck Duck Go...\n",
            "[{'tool_call_id': 'call_29IUu26e4ZFuOXnuGH7bo4Az', 'output': 'Lowry has been a part of the Jets organization since June 25, 2011, when he was selected in the third round, 67 th overall, after putting up 37 points in 36 games with the Swift Current Broncos of ...\\nWinnipeg Jets Captains. Team Names: Winnipeg Jets, Atlanta Thrashers. Seasons: 24 (1999-00 to 2023-24) NHL Playoff Appearances: 7. NHL Championships: 0 (0 Stanley Cup) ... Current Summary/Standings, Current Schedule/Results, Current Leaders, Current Stats. 2023-24, ...\\nLowry will follow Andrew Ladd and Blake Wheeler to serve as the third captain of the new Winnipeg Jets franchise. - Sep 12, 2023. After a season without a captain, the Winnipeg Jets have named ...\\nThe Winnipeg Jets have a new leader, one year after stripping the C from Blake Wheeler and deciding to play without a captain. Adam Lowry, who has been a Jet since 2011 when he was drafted 67th ...\\nWinnipeg played without a captain last season after stripping Blake Wheeler of the title in September. Lowry is entering his 10th season with the Jets, who drafted him in the third round in 2011.'}]\n",
            "Current run status: completed\n",
            "assistant: The current Captain of the Winnipeg Jets is Adam Lowry. He is the third captain of the franchise, following Andrew Ladd and Blake Wheeler.\n",
            "user: Who is the current Captain of the Winnipeg Jets?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_UmID6J7X1BOxP2rHjBeJQWi8'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"Who is the current Captain of the Winnipeg Jets?\", assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY51QtkGNvQe"
      },
      "source": [
        "## Wrapping it All Together\n",
        "\n",
        "Now we can create an Assistant with all of the available tools and see how it responds to various queries!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "HaoQSB7CN74T"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=name + \" + All Tools\",\n",
        "    instructions=instructions,\n",
        "    tools=[\n",
        "        {\"type\": \"code_interpreter\"},\n",
        "        {\"type\": \"retrieval\"},\n",
        "        {\"type\": \"function\", \"function\" : ddg_function}\n",
        "    ],\n",
        "    model=model,\n",
        "    file_ids=[file_reference.id],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2GtwoGDPwp2",
        "outputId": "e276723d-54e1-41ff-8b47-ef725caaabb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: I couldn't find information about the current Captain of the Winnipeg Jets in the document you uploaded. Would you like me to look up this information online for you?\n",
            "user: Who is the current Captain of the Winnipeg Jets?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_TPlvHgusOalsqS3coGziUqnJ'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"Who is the current Captain of the Winnipeg Jets?\", assistant.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QjcxpQ5P-HX",
        "outputId": "43f6a9be-ad9b-4177-92bb-6064dbc0d88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The author of the supplied file is Mary Shelley, and the file appears to be the text of the novel \"Frankenstein\" by Mary Shelley.\n",
            "user: Who is the author of the supplied file?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_C7DcQLPhaO83MGNfrmaHfnG6'"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"Who is the author of the supplied file?\", assistant.id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSKL96nvQIUq",
        "outputId": "e054c800-7c54-4601-d972-4b3c5dc1125d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: requires_action\n",
            "Consulting Duck Duck Go...\n",
            "[{'tool_call_id': 'call_at39cF5e3f1VxmuX2sHlG2I1', 'output': 'Here are some advantages to use du command to check file size in Linux. The du command can show the size of a file in human-readable format, which makes it easier to interpret the results.; The du command can be used to check the size of multiple files at once.; The du command can be used to check the size of directory.; The du command is faster than the ls command when checking the size of ...\\nThe du command can be used to check the size of files, directories, and the total disk space used by the current directory and subdirectories. Run \"du -h\" to see a list of files and folders in a human-readable format. When you use the Linux du command, you obtain both the actual disk usage and the true size of a file or directory.\\nBy default, the block size in most Linux system is 4096 Bytes or 4 KB. A directory in Linux is simply a file with the information about the memory location of all the files in it. You can force ls command to display file size in MB with the --block-size flag. ls -l --block-size=M.\\nTo get the directory size, you use the du command (disk utilization) in the following way: du -sh dirname. You may also use the stat command to get the file size but somehow I feel more comfortable using the ls command. I hope this basic Linux command tip helped you check file sizes in Linux. Terminal Quick Tip.\\nHere is what we see:-rwxr-xr-x 1 root root 172K May 13 2012 /bin/grep. In the above output example, the 172K is the size of the file. The du command provides the same output in a more user friendly way and it hides all other details too: du -h /bin/grep Now du command reporting file size on screen: 172K /bin/grep. Finally, stat command also provide file size: stat /bin/grep Linux stat command ...'}]\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The file \"frankenstein.html\" has a size of 466,919 bytes.\n",
            "user: How many bytes is the provided file?\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'thread_AM26tPWPjiY48oTL1C5i0OyA'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_assistant(\"How many bytes is the provided file?\", assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gm0oYJu7VAjg"
      },
      "source": [
        "####❓ Question\n",
        "\n",
        "Notice that our response can go through multiple paths, given that:\n",
        "\n",
        "What is \"deciding\" to use the tool?\n",
        "\n",
        "Answer - The LLM model associated to the assistant helps to identify the path and tool the assistant to levearage to answer the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrJWQ4XvZ20K"
      },
      "source": [
        "### Adding JSON Mode for More Agentic Behaviour\n",
        "\n",
        "Finally, we have the ability to select tools - all we need to do now is set up a process to allow us to create some kind of loop and make decisions about whether or not the response is complete or not.\n",
        "\n",
        "We'll leverage the OpenAI completions end-endpoint with JSON mode to let us understand when we've adequately answered our user's question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Rzrk8gn2anpe"
      },
      "outputs": [],
      "source": [
        "completed_template = \\\n",
        "\"\"\"\n",
        "Does this response adequately answer the user's query?\n",
        "\n",
        "Please return your response in JSON format - with key: \"completed\" and either True (if completed) or False (if not completed)\n",
        "\n",
        "User Query:\n",
        "{query}\n",
        "\n",
        "Assistant Response:\n",
        "{response}\n",
        "\"\"\"\n",
        "\n",
        "def is_complete(query, response):\n",
        "  completed_response = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": completed_template.format(query=query, response=response),\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "      response_format={\"type\" : \"json_object\"}\n",
        "  )\n",
        "\n",
        "  return completed_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kCQrx03brge",
        "outputId": "2e2a716d-718f-4e06-bf80-a58922180441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: The provided file is 1200 bytes in size.\n",
            "user: How many bytes is the provided file?\n"
          ]
        }
      ],
      "source": [
        "query = \"How many bytes is the provided file?\"\n",
        "\n",
        "thread_id_for_response = use_assistant(query, assistant.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSJs9oDIgBTK"
      },
      "source": [
        "Now we can observe JSON mode in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "MSDsmlDBcYk_"
      },
      "outputs": [],
      "source": [
        "messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "response = messages.data[0].content[0].text.value\n",
        "completed_flag = json.loads(is_complete(query, response).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-SKB6TWf_Ra",
        "outputId": "e2fdb56c-ca8a-4011-ff25-eb55d8dc5d1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'completed': True}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "completed_flag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bivIAVh0dTwA"
      },
      "source": [
        "## 🚧 BONUS CHALLENGE 🚧:\n",
        "\n",
        "Use the components we've constructed so far to build a loop that lets us continue to query the Assistant if the response is not completed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "vtWh_h_WfjuS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating Assistant \n",
            "Querying OpenAI Assistant Thread.\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n",
            "assistant: I couldn't find specific information about the health benefits of daily meditation in the uploaded file. Would you like me to conduct a general search to find information on the topic?\n",
            "user: What are the health benefits of daily meditation?\n",
            "loop number---- 2\n",
            "Current run status: requires_action\n",
            "Consulting Duck Duck Go...\n",
            "[{'tool_call_id': 'call_XHxCOjPsXvlatbrjviwNBGIH', 'output': 'Summary. Self-inquiry and related styles of meditation can help you \"know yourself.\". This can be a starting point for making other positive changes. 5. Lengthens attention span. Focused ...\\nBenefits of meditation includes physical changes to the brain and improved cognitive functioning, such as (Shapiro, 2020): Slowing of brain aging (particularly thinning of the prefrontal cortex) Improved attention. Increased innovation. Better problem-solving.\\nAlthough the practice of meditation is thousands of years old, research on its health benefits is relatively new, but promising. A research review published in JAMA Internal Medicine in January 2014 found meditation helpful for relieving anxiety, pain, and depression. For depression, meditation was about as effective as an antidepressant.\\nMeditation was especially beneficial for people living in high-stress situations. 2. Improves memory and focus. Some types of meditation can also improve your cognitive functioning, especially ...\\nMeditation is a type of mind-body complementary medicine. Meditation can help you relax deeply and calm your mind. During meditation, you focus on one thing. You get rid of the stream of thoughts that may be crowding your mind and causing stress. This process can lead to better physical and emotional well-being.'}]\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: in_progress\n",
            "Current run status: completed\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'completed': True}"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### YOUR CODE HERE\n",
        "query = \"What are the health benefits of daily meditation?\"\n",
        "thread_id_for_response = use_assistant(query, assistant.id)\n",
        "messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "response = messages.data[0].content[0].text.value\n",
        "completed_flag = json.loads(is_complete(query, response).choices[0].message.content)\n",
        "\n",
        "num_iterations = 2\n",
        "while (not completed_flag[\"completed\"]) and num_iterations < 5:\n",
        "    print(\"loop number---- \" + str(num_iterations))\n",
        "    #use the same thread and re-run\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread_id_for_response,\n",
        "        assistant_id=assistant.id,\n",
        "    )\n",
        "\n",
        "    run = wait_for_run_completion(thread_id_for_response, run.id)\n",
        "\n",
        "    if run.status == 'requires_action':\n",
        "        run = submit_tool_outputs(thread_id_for_response, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
        "        run = wait_for_run_completion(thread_id_for_response, run.id)\n",
        "    \n",
        "    messages = client.beta.threads.messages.list(thread_id=thread_id_for_response)\n",
        "    response = messages.data[0].content[0].text.value\n",
        "    completed_flag = json.loads(is_complete(query, response).choices[0].message.content)\n",
        "    num_iterations +=  1\n",
        "\n",
        "completed_flag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJjYm6gnfWrS"
      },
      "source": [
        "# Make Sure You Delete Resources\n",
        "\n",
        "Make sure you delete all the resources you created!\n",
        "\n",
        "This function will help you do so!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "62b49AleR6m_"
      },
      "outputs": [],
      "source": [
        "file_deletion_status = client.beta.assistants.files.delete(\n",
        "  assistant_id=assistant.id,\n",
        "  file_id=file_reference.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
